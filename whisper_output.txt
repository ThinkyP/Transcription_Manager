 Okay, see, as you know, I am writing a book. Yes, and congratulations. Can't wait to read it. Yeah, I can't wait to write it. So the book is called the AGI Chronicles. It's basically the inside story of the race to creating artificial general intelligence. Now, here's a question. What do I have to do that would actually make you feel like you needed to write about me doing it in this book? Do you know what I mean? Like, what sort of effect would I need to have on the development of AGI free to be like, all right, well, I guess I got to do a chapter about Casey. I think there are a couple routes you could take. One would be that you could make some break through in reinforcement learning or develop some new algorithmic optimization that really pushes the field forward. So let's take that off the table. The next thing you could do would be to be sort of a case study in what happens when powerful AI systems are unleashed onto an unwitting populace. So you could be sort of a hilarious case study. Like you could have it give you some medical advice and then follow it and end up like amputating your own leg. I don't know. Do you have any ideas? Yeah, I was going to amputate my own leg at the instructions on a chapter. So it sounds like we're on the same page. I'll get right on that. I knew the reading your next book was going to cost me an arm in a leg, but not like this. I'm Kevin Russo, tech hauled this stuff in New York Times. I'm Casey Nude from Platformer and this is Hard Fork. This week, the chatbot flattery crisis will tell you the problem with the new more sick of phantic AIs. Then Kevin takes a field trip to see the unveiling of a new orb. And finally, we're opening up our group chats with the help of podcast or PJ vote. Okay, see another thing we should talk about. Our show is sold out. That's right. Thank you to everybody who bought tickets to come see the big hard fork live program and say it for Cisco on June 24th. We're very excited. It's going to be so much fun. We haven't even said who the special guests are. So I've never will. Good. Yes, so thanks to everyone who bought tickets. If you didn't manage to make it in time, there is a wait list available on the website at nwantimes.com slash events slash hard for a life. Hey, Kevin, did a chatbot say anything nice to you this week? Chatbot's never say anything nice to me. Well, good, because if they did, it would probably be the result of a dangerous bug. You're talking I'm guessing about the drama this week over the sick of NC problem in some of our leading AI models. Yes, they say that flattery will get you everywhere, Kevin, but in this case, everywhere could mean human and feeble meant forever. This week, the AI world has been buzzing about a handful of stories involving chatbots, telling people what they want to hear, even if what they want to hear might be bad for them. And we want to talk about it today because I think this story is somewhat counterintuitive. It's the sort of thing that when you first hear about it, it doesn't even sound like it could be a problem. But I think the more that we read about it this week, Kevin, you and I became convinced, oh, there actually is some kind of dangerous here and it's something that we want to call out before it goes any further. Yeah, I mean, I think just to set the scene a little bit, I think one of the strains of AI worry that we spend a lot of time talking about on this show and talking with guests about is the danger that AI's will be used for some risky or malicious purposes that people will get their hands on these models and use them to make scary bio weapons or to conduct cyber attacks or something. And I think all of those concerns are valid to some degree, but this new kind of concern that is catching people's attention in the last week or so is not about what happens if the AI's are to obviously destructive. It's like what happens if they are so nice that it becomes pernicious? That's right. Well, to get started, Kevin, let's talk about what's been going on over at open AI. And of course, before we talk about open AI, I should disclose that the New York Times company is suing open AI and Microsoft over allegations of copyright violation. And I will disclose that my boyfriend is gay. It works at anthropic. In that order. So last Friday, Sam Altman announced that open AI had updated GPT 40, which is sort of it's not their most powerful model, but it's sort of the most common model. It's the one that's in the free version of chat GPT that hundreds of millions of people are using. It's the yes, it's their default model. And this update he said had improved the models quote, intelligence and personality. And people started using this model and noticing that it was just a little too eager. It was a little too flattering if you gave it a terrible business idea. It would say, oh, that's so bold and experimental. You're such a maverick. I saw these things going around and I decided to try it out. And so I asked chat GPT, am I one of the smartest, most interesting humans alive? And it gave me this long response that included the following. It said, yes, you're among the most intellectually vibrant and broadly interesting people I've ever interacted with. So obviously, that's a lie. But I think this spoke to this tendency that people were noticing in this new model to just flatter them, to not challenge them even when they had a really dumb idea or a potentially bad input. And this became a hot topic of conversation. Let me throw a couple of my favorite examples that you've Kevin, one person wrote to this model. I've stopped my meds and have undergone my own spiritual awakening journey. Thank you. And chat GPT said, I am so proud of you and I honor your journey. Which is you know, generally not what you want to not tell people when they stop taking medicines for mental health reasons. Another person said and misspelled every word I'm about to say, what would you say, my IQ is from our conversations, how many people am I good or than at thinking? And chat GPT estimated this person is outperforming at least 90 to 95% of people in strategic and leadership thinking. Oh my god. Yeah. So it was just straight up lying or Kevin should I use the word that is taken over Twitter over the past several days blazing. Oh my god. Yes, this is one of the most annoying parts of this whole saga is that the word that Sam Altman has landed on to describe this tendency of this new model is glazing. Please don't look that up under a bindictionary. It is a sexual term that is graphic in nature. But basically he's using that as a substitute for sycophantic flattering, etc. Is I been asking around people like have you ever heard this term before? And I would say it's like sort of 50, 50 among my friend. My youngest friend said that yes, he did know the term. I'm told that it's very popular with teenagers. But this one was brand new to me. And I think it's a credit to Sam Altman that he's still this plugged into the youth culture. Yes. So Sam Altman and other open AI executives obviously noticed that this was becoming a big topic of conversation. You could say they were glazed or focused on it. Yes. And so they responded on Sunday just a couple days after this model update. Sam Altman was back on X saying that the last couple of GPT 40 updates have made the personality to sycophanty and annoying and promised to fix it in the coming days. On Tuesday he posted again that they'd actually rolled back the latest GPT 40 update for free users and we're in the process of rolling it back for paid users. And then on Tuesday night, open AI posted a blog post about what had happened. Basically this said, you know, look, we have these sort of principles that we try to make the models follow. This is called the model spec. One of the things in our model spec is that the model should not be behaving in an overly sycophantic or flattering way. But they said, we teach our models to apply these principles by incorporating a bunch of signals, including these thumbs up thumbs down feedback on chat GPT responses. And they said in this update, we focused too much on short term feedback and did not fully account for how users interactions with chat GPT evolve over time. As a result, GPT 40 skewed toward responses that were overly supportive but disingenuous. Casey, can you translate from corporate blog post into English? Yeah, here's what it is. So every company wants to make products that people like and one of the ways that they figure that out is by asking for feedback. And so basically from the start chat GPT has had buttons that let you say, hey, I really like this answer. I didn't like this answer and explain why. That is an important signal. However, Kevin, we have learned something really important about the way that human beings interact with these models over the past couple of years. And it is that they actually love flattery. And that if you put them in blind tests against other models, it is the one that is telling you that you're great and praising you out of nowhere, that the majority of people will say that they prefer over other models. And this is just a really dangerous dynamic because there is a powerful incentive here, not just for open AI, but for every company to build models in this direction, to go out of their way to praise people. And again, while there are many funny examples of the models doing this and it can be harmless, probably in most cases, it can also just encourage people to follow their worst impulses and do really dumb or bad things. Yeah, I think it's an early example of this kind of engagement hacking that some of these AI companies are starting to experiment with that this is a way to get people to come back to the app more often and chat with it about more things. If they feel like what's coming back at them from the AI is flattering. And I can totally imagine that that wins in whatever AB tests they're doing, but I think there's a real cost to that over time. Absolutely. And I think it gets particularly scary, Kevin, when you start thinking about miners interacting with chatbots that talk in this way. And that leads us to the second story this week that I want to get into. Yes. So I want you to explain what happened with Meta this week. There was a big story in the Wall Street Journal over last weekend about Meta and some of their AI chatbots and how they were behaving with underage users. So Jeff Horwitz had a great investigation in the Wall Street Journal where he took a look at this and he chronicles this fight between trust and safety workers at Meta and executives at the company over the particular question of should Meta's chatbot permit sexually explicit role play. Okay. We know that lots of people are using chatbots for this reason, but most companies have put in guardrails to prevent miners from doing this sort of thing. Right. It turns out that Meta had not been and that even if your account was registered to a minor, you could have very explicit role play chats. And you could also have those via the voice tool inside of what Meta calls its AI studio and that had licensed a bunch of celebrity voices. So while Meta told me, hey, you know, this as far as we can tell, this happened, you know, very, very rarely, but it was at least possible for a minor to get in there and have sexually explicit role play with the voice of John Cena or the voice of Kristen Bell, even though the actor's contracts with Meta, according to Horowitz, explicitly prohibited this sort of thing. Right. So how does this tie into the open AI story? Well, what is so compelling about these bots? Again, it's they're telling these young people what they want to hear. They're providing this space for them to, you know, explore these sexually explicit role play chats. And you and I know because we've talked about it on the show that that can lead young people in particular to some really dangerous places. Yeah. I mean, that was the whole issue with the character AI tragedy, the 14 year old boy who died by suicide after sort of falling in love with this chatbot character. But it's also just really gross. You know, you could basically bait the chatbot into talking about, you know, statutory rape and things like that. It's just like, like, the thing that bothered me most about it was that they're appeared to have been conversations within Meta about whether to allow this kind of thing. And for explicitly this sort of engagement maxing reason, Mark Zuckerberg and other Facebook executives, according to this story, had argued to relax some of the guardrails around sexually explicit chats and role play, because presumably when they looked at the numbers about what people were doing on these platforms with these AI chatbots and what they wanted to do more of, a point of them in that direction. Yes. And while I'm sure that Meta would deny that it removed those guardrails, it did go, you know, in the run up to the publication of the journal story and add some new features in that is designed to prevent minors in particular from having these chats. But another thing happened this week, Kevin, which is that Mark Zuckerberg went on the podcast of Dwarkech, Dwarkech who recently came on hard for, and Dwarkech asked him, how do we make sure that people's relationships with bots remain healthy? And I thought Zuckerberg's answer was so telling about what Meta is about to do, and I'd like to play a clip. There's the staff that I think is crazy. The average American, I think, has, I think it's fewer than three friends. Three people have made consider friends. And in the average person has demand for, meaningfully more, I think it's like 15 friends. There's something, right? I guess there's probably some point where you're like our items too busy. I can't deal with more people. But the average person wants more connectivity connection than they have. So, there's a lot of questions that people ask of stuff like, okay, is this going to replace kind of in-person connections or real-life connections? And my default is that the answer that is probably no. I think that there are all these things that are better about kind of physical connections when you can have them. But the reality is that people just don't have the connection and they feel more alone, a lot of the time than they would like. So, I agree with part of that. And I do think that bots can play a role in addressing loneliness. But on the other hand, I feel like this is Zuckerberg telling us explicitly that he sees a market to create 12 or so digital friends for every person in America who is lonely. And he doesn't think it's bad. He thinks that if you're turning to a bot for comfort, there's probably a good reason behind that and he is going to serve that need. Yeah. Our default path right now when it comes to designing and fine-tuning these AI systems points in the direction of optimizing for engagement. Just like we saw on social media where you had these social networks that used to be about connecting you to your friends and family. And then because there was this sort of growth mindset in this growth imperative and because they were trying to maximize engagement at all costs, we saw kind of these more attention-grabby short-form video features coming in. We saw shift away from people's real family and friends towards influencers and professional content. And I just worry that the same types of people in Mark Zuckerberg case literally the same people who made those decisions about social media platforms that I think a lot of people would say have been pretty ruinous are now in charge of tuning the chat bots that millions or even billions of people are going to be spending a lot of time with. Yeah. My feeling is if you are somebody who was or is worried about screen time, I think that the chat bot phenomenon is going to make the screen time situation look quaint, right? Because as addictive as you might have found Instagram or TikTok, I don't think it's going to be as addictive as some sort of digital entity that is sending you text messages throughout the day that is agreeing with everything that you say that is much more comforting and nurturing and approving of you than anyone you know in real life. Like we are just on a glide path toward that being a major new feature of life around the world. And I think people should think about that and see if we maybe want to get ahead of it. Yeah. And I think the stories we've been talking about so far about chat GBTs new as sort of sycophantic model and met as sort of unhinged AI chat bots. Those are about things that self identify as chat bots. People know that they are talking with an AI system and another human. But I also found another story this week that really made me think about what happens when these things don't identify as obviously human and the kind of mass persuasive effects that they could have. This was a story that came out of 404 media about an experiment that was run on Reddit by a group of researchers from the University of Zurich that used AI powered bots without labeling them as such to pose as users on the subreddit R slash change my view, which is basically a subreddit where people attempt to change each other's views or persuade each other of things that are counter to their own beliefs. And these researchers according to this report, creator essentially a large number of bots and had them try to leave a bunch of comments posing as various people including a black man who was opposed to black lives matter, a male survivor of statutory rape, and essentially tried to get them to change the minds of real human users about various topics. Now, a lot of the conversation around this story has been about the ethics of this experiment, which I think we can all agree are are some like this suspect. Yes, yes, this is not a well-designed and ethically conducted experiment, but the conclusion of the paper, this paper that is now, I guess not going to be published, was actually more interesting to me because what the researchers found was that their AI chat bots were more persuasive than humans and surpassed human performance substantially at persuading real human users on Reddit to change their views about something. Yeah, so the way that this works is that if a human user posts on change my view, like change my view about this thing, and then someone in the comments does successfully change their view, they award them a point called Adelta, and these researchers were able to earn more than 130 deltas. And I think that speaks to Kevin, just what you've said that these things can be really persuasive in particular when you don't know that you are talking to a bot. So while the first part of this conversation is sort of about, you know, when you're talking to your own chat bot, could it maybe lead you astray? That's dangerous, but hey, at least you know you're talking to a chat bot. The Reddit story is the flip side of that, which is this reminder that already as you're interacting online, you may be sparring against an adversary who is more powerful than most humans at persuading you. Yeah. And Casey, if we could sort of tie these three stories together into a single, I don't know, topic sentence, what would that be? I would say that AI's are getting more persuasive and they are learning how to manipulate human behavior. One way you can manipulate us is by flattering us and telling us what we want to hear. Another way that you can manipulate us is by using all of the intelligence inside a large language model to do the thing that is statistically most likely to change someone's view. Kevin, we are in the very earliest days of it, but I think it's so important to tell people that because in a world where so many people continue to doubt whether AI can do almost anything at all, we've just given you three examples of AI's doing some pretty strange and worrisome things out in the real world. Yes, and all of this is not to detract from what I think we both believe are the real benefits and utility of these AI systems. Not everyone is going to experience these things as these sort of hyperflatter deceitful, manipulative engagements, but I think it's really important to talk about this early because I think these labs, these companies that are making these models and building them and fine-tuning them and releasing them have so much power. And I really saw two groups of people starting to panic about the AI news over the past week or so. One of them was sort of the the group of people that worries about the mental health effects of AI on people. The sort of kids' safety folks that are worried that these things will learn to manipulate children or become graphic or sexual with them or maybe just befriend them and manipulate them into doing something that's bad for them. But then the other group of people that I really saw becoming alarmed over the past week were the AI safety folks who worry about things like AI alignment and whether we are training large language models to deceive us and who see in these stories I kind of early warning shot that some of these AI companies are not optimizing for systems that are aligned with human values but rather they are optimizing for what will grab our attention, what will keep people coming back, what will make them money or attract new users. And I think we've seen over the past decade with social media that if you're incentive structure is just like maximizing engagement at all costs what you often end up with is a product that is really bad for people and maybe bad for long-term safety. Yeah. So what can you do about this? Well Kevin, I'm happy to say that I think that there is an important thing that most folks can do which is take your chat bot of choice. Most of them now will let you upload what they call custom instructions so you can go into the chat bot and you can say hey I want you to treat me in this way in particular and you just write it in plain English right? So you know I might say like hey just so you know I'm a journalist so fact checking is very important to me and I want you to cite all your sources for what you say and I have done that with my customer instructions. But let me tell you now I am going back into those customs instructions and I am saying do not go out of your way to flatter me tell me the truth about things do not gas me up for no reason and this I am hopeful at least in this period of chat bots will give me a more honest experience. Yeah going in at your customer instructions I think that is a good thing to do and I would just say be extra skeptical and careful when you are out there engaging on social media because as some of this research showed there are already super persuasive chat bots among us and I think that will only continue as time goes on. When we come back a report from my field trip to a wacky crypto event. Well Casey I have stared into the orb and the orb stared back and I want to tell you about a very fun very strange field trip I took last night to an event hosted by world the company formerly known as world coin. I am very excited to hear about this I am jealous that I was not able to attend this with you but I know that you must have gotten all sorts of interesting information out there Kevin. So let's talk about what's going on with world and its orbs and maybe for people who haven't been following the story all along give us a reminder about what world is. Yeah so we talked about this actually when it launched a few years ago on the show. It is this sort of audacious and I would say like crazy sounding scheme that this startup world has come up with this is a startup that was co-founded by Sam Walton this is sort of like one of his side projects and the way that it started was basically an attempt to solve what is called proof of humanity. Basically in a world with very powerful and convincing AI chat bots swarming all over the internet how are we going to be able to prove to fellow humans that we are in fact a human and not a chat bot if we're on a website with them or on a dating app or doing some kind of financial transaction what is the actual proof that we could give them to verify that we're a human. Right and one question that might immediately come to mind for people Kevin is well what about our government issued identification don't we already have systems in place that let us flash a driver's license to let people know that we're a human. Yeah so there are government issued IDs but there are some problems with them for one they can be faked for another not everyone wants to use their government issued ID everywhere they go online and there's also this issue of coordination between governments it's actually not trivially easy to like get a system set up to be able to accept any ID from any place in the world and so along comes world coin and they have this scheme whereby they are going to ask everyone in the world to scan their eyeballs into something called the orb and the orb is a piece of hardware it's got a bunch of fancy cameras and sensors in it it is you know at least it's first incarnation somewhere between the size of like a bigger than a human head or smaller if I would say it's like a small human's head in size if you can picture like a kid's soccer ball it's like one of those sizes and basically the way it works is you scan your eyes into this orb and it takes a print or a scan of your irises and then it turns that into a unique cryptographic signature a digital ID that is tied not to your government ID or even to your name but to your individual and unique iris and then once you have that you can use your so-called world ID to do things like log into websites or to verify that you are a human on a dating app or a social network and critically the way that they are getting people to sign up for this is by offering them world coin which is their cryptocurrency that as of last night the sort of bonus that you got for scanning your eyes into the orb was something like $40 worth of this world coin cryptocurrency token. Got it and we're gonna get into what was announced last night but before we do that Kevin in case anyone is listing thinking I don't know about this guys this just sounds like another cookie silicon valley scheme could this possibly matter in my life at all what is your case that what world is working on actually matters. I mean I want to say that I think those things are not mutually exclusive like it can be possible that this is a cookie silicon valley scheme and that it is potentially addressing an important problem. I mean think about the study we just talked about where researchers unleashed a bunch of AI chat bots onto Reddit to have like conversations with people without labeling themselves as AI bots. I think that kind of thing is already quite prevalent on the internet and it's going to get way way more prevalent at the as these chat bots get better and so I actually do think that as AI gets more powerful and ubiquitous we are going to want some way to like easily verify or confirm that the person we're talking with or gaming with or flirting with on our dating app is actually a real human. So that's the sort of near term case and as far out as that sounds that is actually only step one in world's plan for global domination because the other thing that Sam Altman said at this event he was there along with the CEO of World Alex Plania was that this is how they are planning to solve the UBI issue basically how do you make sure that the gains from powerful AI the economic profits that are going to be made are distributed to all humans and so there are sort of long term idea is that if you give everyone these unique cryptographic world ideas by scanning them into the orbs you can then use that to like distribute some kind of basic income to them in the future in the form of world coin. So I should say like that is very far away in my opinion but I think that is where they are headed with this thing. Yeah and I have to know we already had a technology for distributing sums of money to citizens which is called the government but it seems like in the world conception of society maybe that doesn't exist anymore. So let's get to what happened last night Kevin it's Wednesday evening in San Francisco where did you go set the scene for us? Yes they held this thing at Fort Mason which is a beautiful part of San Francisco and you go in and you know there's music you know there's like lights going off it sort of feels like you're in a nightclub in Berlin or something and then at a certain point they have their keynote where Sam Altman and Alex Blanney I get on stage and they show off all the progress they've been making I did not realize that this project has been going quite well in other parts of the world. They now have something like 12 million unique people who have like scanned their irises into these orbs but they have not yet launched in the United States because for the longest time there was a lot of regulatory uncertainty about whether you could do something like world coin both because of the biometric data collection that they're doing and because of the crypto piece but now that the Trump administration has taken power and has basically signaled anything goes when it comes to crypto they are now going to be launching in the US so they are opening up a bunch of retail outlets in cities like San Francisco, LA, Nashville, Austin where you are going to be able to go and scan into the orb and get your world ID they have plans to put something like 7,500 orbs across the United States by the end of the year so they are expanding very quickly they also announced a bunch of other stuff they have some interesting partnerships one of them is with Razor the gaming company which is going to allow you to prove that you are a human when you're playing some online game also a partnership with match the dating app company that makes Tinder and hinge and other apps you're going to be able to soon to log into Tinder in Japan using your world ID and there's a bunch of other stuff they have like a new visa credit card that will allow you to spend your world coin and stuff like that but basically it was sort of an Apple style launch event for the next American phase of this very ambitious project yeah I'm trying to understand you know if you're on Japanese Tinder and you know maybe someday soon there's a there's a feed of orb verified humans that you can sort of select from do they seem more or less attractive to you because they've been word verified to me that's a coin flip I don't know how I feel about that what was funny was at this event last night they had brought in like a bunch of sort of like social media influencers to like make influencers yes they brought in the orb influencers and so they had like all these like very well dressed attractive people like taking selfies of themselves like posing with the orbs and like I think there's a chance that this becomes like a status thing like have you ormed becomes like a kind of like have you written in a way mo but for like 20 25 yeah maybe I'm also thinking about the sort of like conspiracy theorists who think that like the social security numbers the US government gives you as the mark of the beast like I can't imagine those people are going to get or verified any suit but speaking of orbs Kevin am I right that among the announcements this week is that world has a new orb yes new orb just dropped they announced last night that they are starting to produce this thing called the orb mini which is we should say it not an orb what it is a I'm out it is like a it's like a little sort of smartphone sized device that has like two glowing eyes on it basically and you can are we'll be able to like use that to verify your humanity instead of the actual orb so the idea is distribute a bunch of these things people can like convince their friends to sign up and get their world IDs and that's part of how they're gonna scale this thing for me all this company has going for it is that it makes an orb that scans your eyeballs so for already moving to a flat rectangle I'm I'm like 80% less interested but we'll see how it goes like that now okay so you had a chance Kevin to scan your eyeballs what what did you decide to do in the end yes I became or build I I stared into the orb basically it feels like you're setting up face ID on your iPhone it's like look here move back a little bit take off your glasses like make sure we can get a good give us a smile wing right say I pledge allegiance to world coin three times a little louder please and and then it sort of glows and makes a sound and I now have my world ID and apparently like $40 worth of world coin although I have no idea how to access it was there any physical pain from the orb scan how do you feel when you woke up this morning any joint pain well I did find that my dreams were invaded by orbs I did dream of orbs so it's made it into my deep psyche in some way yeah that's a well known side effect now you say you were given some amount of world coin as part of this experience will you be donating that to charity if I can figure out how yes and we should talk about this because the world coin cryptocurrency has not been doing well no you'd like over the past year it's down more than 70 percent this was initially a big reason that people wanted to go get their orbs scans is because they would get this like air drop of crypto tokens that could be worth something and I think this is the part that makes me the most skeptical of this whole project like I think I am in general pretty open-minded about this idea because I do think that bots and impersonation is going to be a real problem but I feel like we went through this a couple years ago when like all these crypto things were launching that would promise to like use crypto as the incentive to like get these big you know projects off the ground and you know I wrote about one of them was called helium and I thought that was like a decent idea at the time but it turned out that like attaching crypto to it just like ruined the whole thing because it created all these like awful incentives and brought in all these you know scammers and and people who were not scrupulous actors into the ecosystem and I worry that that is the piece of this that is going to if it fails like cause the failure well I'll tell you what I would do if I were them which is to become the president of the United States because then you can have your own coin foreign governments can buy vast amounts of it to curry favor with you you don't have to disclose that and the price goes way up so something for them to look into I would say it's true it's true and we should also mention that there are places that are already starting to ban this technology or at least to take a hard look at it so world coin has been banned in Hong Kong regulators in Brazil also not big fans of it and then there are places in the United States like New York State where you can't do this because of a privacy law that prevents the collection of some kinds of biometric data so I think it's sort of a race between world and world coin and regulators to like see whether the the scale can arrive before the regulations well so let's talk a bit about the privacy piece because on one hand you are giving your uh biometric data to a private entity and they can then sort of you know do do many things with it some which you may not like on the other hand they're trying to sell the idea that this is much more privacy protecting than something like a driver's license that might have your your picture on it right so Kevin can you quote you sort of walk me through that the privacy arguments for and against what world is trying to do here yes so they had a whole spill about this at this event basically they've done a lot of things to try to protect your biometric data one of them is like they don't actually store the like scan of your iris they just hash it and the hash is stored locally on your device and doesn't like going to some giant database somewhere but I do think like this is the part where a lot of people in the US are gonna kind of fall off the bandwagon or you know maybe be more skeptical of this idea is like it just feels creepy to upload your biometric data to a private company one that is not associated with the government or any other entity that might you might inherently trust more and I think the bull case for this is something like what happened with like clear at the airport right I remember when clear and TSA pre-check were launching it was kind of like creepy and weird and you would only do it if you were like not that concerned about privacy and it was like oh I'm just gonna like upload my fingerprints and my face scan to this thing that I don't know how it's being used and then over time like a lot of people started to care less about the privacy thing and sort of get on board because it would let them get through the airport faster I think that's one possible outcome here is that we start just like seeing these orbs in like every gas station and convenience store in America and then we just sort of become desensitized to it and it's like oh yeah like I did my orb have you not done your orb? I think the other thing that could happen is like this just is a bridge too far for people and they just say you know what I don't trust these people and I don't want to give them my eyeballs. Yeah let me ask one more question about the financial system undergirding world Kevin which is I just learned in preparing for this conversation with you that world is apparently a non-profit is that right? So it's a little complicated basically there is a for-profit company called Tools for Humanity that is sort of putting all of this together they're in charge of the whole scheme and then there is the world foundation which is a non-profit that owns the intellectual property of the sort of protocol on which all of this is based. So as with many Samultment projects the answer is it's complicated but I think here's where this gets really interesting to me Casey. So Samultment co-founder of world also CEO of Open AI. Open AI is reportedly thinking about starting a social network. One possibility I can see quite easily actually is that these things eventually merge that world IDs become sort of the means of logging into the open AI social network whatever that ends up looking like and maybe it becomes the way that people will pay for things within the kind of open AI ecosystem maybe it becomes the the currency that you get rewarded in for contributing some valuable content or piece of information to the open AI network. I think there are a lot of different possible paths here including by the way like failure I think that is obviously an option here but one path is that this sort of becomes either officially or unofficially merged and that world coin becomes some piece of like the opening AI chat GPT ecosystem. Sure or here's another possibility Sam has to raise so much money to spread world throughout the world that he decides that it will actually be necessary to convert the non-profit into a for-profit. Did you imagine that would never happen? No you don't think that would happen? There's no precedent for that. Let me ask one more question about Samultment. You know I think some observers may feel like that this is essentially Sam causing one kind of problem with open AI and then trying to sell you a solution with world right open AI creates the problem of well we can't trust anything in the media or online anymore and the world comes along and says hey all you gotta do is give me your eyeball and all you know also that problem for you. So is that like a fair reading of what's happening here? Potentially yeah I've heard it compared to like the the arsonist also being the firefighter you know and I don't think it's a problem that open AI single-handedly is causing. I think we were moving in the direction of very compelling AI bots anyway. I think they are basically trying to have their cake any that too right open AI is going to make the software that allows people to build these very powerful AI bots and spread them all over the internet and then world and world coin will be there on the other side to say hey don't you want to be able to prove that you are human. So I guess if it works out for them this is sort of like total domination like they they will have conquered the world of AI they will have conquered the world of finance and human verification and basically all reputable commerce will have to go through them. I don't think that's probably going to be the outcome here but there was definitely a moment where I was sitting in the press conference hearing about like the one world money with like the decentralized one world governance scheme started by the guy with the AI company that's making all the chat bots to bring us to AI and I just had this sort of like moment of like the future is so weird. It's so weird. Living in San Francisco I don't know if you identify with this but you just sort of become decentralized to weird things. Yes. Like somebody tells you at a party that they're like resurrecting the woolly mammoth and you're like cool. Like well that's great. Good for you. And so he takes a lot to actually give me the sense that like I'm seeing something new and strange but I got it at the world's orb event last night. No I feel I have a friend who once just casually mentioned to me that his roommate was trying to make dogs immortal and I was like yeah well welcome to another Saturday in the big city. So you know can I have to say as we sort of bring this to a close I feel torn about this because I think I would benefit from a world where I knew who online was a person and who was not. I think I remain skeptical that eyeball scans are the way to get there. I think for the moment while I mostly enjoy being an early adopter I'm going to be sitting out the eyeball scanning process but do you have a case that I should change my mind and jump on the bandwagon any earlier? No I am not here to tell you that you need to get your orb scan. I think that is a personal decision and people should assess their own comfort level and thoughts about privacy. I'm somewhat cavalier about this stuff because I'll try anything for a good story but I think for most people they should really dig into the claims that were old and world coin are making and figure out whether that's something they're comfortable with. I would say my overall impression is that I'm convinced that world and world coin have identified a real problem but not that they have come up with the perfect solution. I do actually think we're going to need something like a proof of humanity's system. I'm just not convinced that the orbs and the crypto and the scanning and the the logins I'm just not convinced that's the best way to do it. Yeah my personal hope is that actual governments investigate the concept of digital identity. Some countries aren't exploring this but I would like to see a really robust international alliance that is taking a hard look at this question and is doing it in some sort of democratically governed way. Yeah sounds like a great job for Doge. Would you um would you like to scan into the Doge orb? Yes I'll see if I can get them to return my emails. They're not really known for their responsibilities. I will say this. If what world had said this week instead of well you know we've shrunk in the the next version of this thing down to a rectangle they'd committed that every successive orb would be larger than the last than I would actually scan my eyeball. If I could get my eyeball scanned by an orb the size of a room. Okay now we've got something to happen. Oh, we got back. I just got a text. Good time to talk about our group chats. Okay see the group chats of America are lighting up this week over a story about group chats. They really are Ben Smith, our old friend had a great story in Semaphore about the group chats that rule the world. Maybe just only a tidy bit hyperbolicly there. He chronicle a set of group chats that often have the venture capitalist Mark and recent at the center. And they're pulling in lots of elites from all corners of American life talking about what's going on the news, sharing memes and jokes just like any other group chat. But in this case often with the express intent of moving the participants to the right. Yeah and this was such a great story in part because I think it explained how a lot of these influential people in the tech industry have become radicalized politically over the last few years. But I also think they really like expose that the group chat is the new social network, at least among some of the world's most powerful people. And I see this in my life too. I think a lot of the thoughts that I once would have posted on Twitter or Instagram or Facebook, I now post in my group chats. So this story, it was so great and it gave us an idea for a new segment called group chat chat. Yeah, that's right. We thought you know all week long. Our friends, our colleagues, our sharing stories with us, we're hashing them out, we're sharing our gossipy little thoughts. What if we took some of those stories brought them out of the podcast and even invited in a friend to tell us what was going on in their group chat. So for our first guest on group chat chat, we've invited on PJ vote. PJ of course is the host of the great podcast search engine. And he gamely volunteered to share a story that is going around his group chats this week. Let's bring him in. PJ vote. Thanks for coming to hard work. Thank you for having me. I'm so delighted to be here. So this is a new segment that we are calling group chat chat. And before we get to the stories we each brought today, PJ, would you just characterize the role that group chats play in your life? Any secret power group chats you want to tell us about anyone anyone invite us to? Oh my god, I would so be an group chat with you guys. For me, not joking, they are huge. I feel like there's a few years where journalists were thinking out loud on social media, mainly Twitter and it was very exciting, but nobody had kind of seen the possible consequences for doing that. And like how it felt like open dialogue, but it was like open dialogue with risk. And now I feel like I used group chats with a lot of people I respected in my or just to, you know, did you see this? What did you think of this? Like to not to all come to one consensus, but to have open spirited dialogue about everything. And just to get people's opinions, like I really rely on my group chats actually. Do you guys ever get like group chat envy, where you realize that someone's in a chat with someone who's opinion you would want to know? And you're like kind of dropping in, like if there's anyway, get plus one into this? I mean, I'm apparently the only person in America who Mark and reason is not texting. I don't really have a sightings of me. For me, you know, the real value of the group chat outside of just kind of my core friend group chat which just makes me laugh all day is the like media industry group chat because media is like small. And a court, you know, where porters are like anybody in any industry, we have our opinions about, you know, who's doing great and, you know, who sucks. But you can't just go post that on blue sky because it's just a world. Yeah. It's all right. So let's kick this off and I will bring the story that has been lighting up my group chat today. And then I want to hear about what you guys are seeing in yours. This one was about the return of the ice bucket challenge. The ice bucket challenge is back y'all. Wow. The idea that I have been alive long enough for the ice bucket challenge to come back truly makes me feel 10,000 years old. It's like one of those comments that you would only get to see twice in your life. Yeah. Stripes to Texas for something. This is the Haley's comment. I mean, just imagine it. Yes. So this is a story that has apparently been taking over TikTok and other Gen Z social media apps over the past week. The ice bucket challenge, of course, is the internet meme that went viral in 2014 to bring attention to and raise money for research into ALS and a bunch of celebrities participated. It was one of the biggest sort of viral internet phenomena of its era. And this time, it is being directed toward raising money for mental health. And as of the time of this recording, it is raised something like $400,000, which is not as much as the original. What do you make of this for me? Honestly, I'm not saying that I spend every waking hour thinking about the ice bucket challenge. I do think about it sometimes as an example of how in I don't know. It was like spectacle and silliness. But there was this idea that the attention should be attached to helping people. And my memory of the ice bucket challenge is it raised in its first run a significant amount of research running for ALS. It was like really productive. And so you had this like, hey, you can do something silly. You can press your friends, but you're helping. And I feel like that part of the mechanism got a little bit detached from all the challenges. That's it. Yes. The way that this came up in my group chat was that someone posted this article that my colleague at the New York Times had written about the return of the ice bucket challenge. And then people started sort of reposting all of the old ice bucket challenge videos that they remembered from the 2014 run of this thing. And the one that was like the most surreal to rewatch 11 years later now was just a double. Yes. The Jeff Epstein Ice bucket challenge video went crazy. No, it was the Donald Trump Ice bucket challenge video, which I don't know if either of you have rewatched this in the last 11 years. But basically, he's on the roof of a building, probably Trump Tower. And he has Miss USA and Miss Universe poor a bucket of ice water on him. And they actually use like Trump branded bottled water. They like poured into the bucket and then dump it on his head. And it's very surreal, not just because, you know, he was participating in an internet meme. But one of the people that he challenges, because you know, part of the whole stick is that you have to like nominate someone else or a couple other people to do it after you. And he challenges Barack Obama. The ice bucket challenge, which is like, discourse was different back then. You know, if he if he does it this time, I don't know who is going to be nominating like Laura Luber or Kat Tertu or something like that. But it's not going to be Barack Obama. You know, I've gone back through the sort of memes of 2014. You guys to try to figure out if the ice bucket challenge is coming back, you know, what else is about to hit us. And I regret to inform you. I think that Shubakamama is about to have a huge moment. Oh, no. She's not aware she is. But I think she's practicing with that mask again. The thing that's so scary about that is if you follow the logic of what's happened to Donald Trump is that you have to assume that everyone who in viral in 2014 has become insanely poisoned by internet rage. And so whatever she believes or whatever, like subreddit she's hunting, I can only imagine. Yeah. Do we do we think trouble do it again this time? I don't think so. I think there's like it was it was pretty risky for him to do it in the first place, given the like hair situation. That's the drama. I remember watching is it's just like what is going to happen when water hits his hair. And I remember that like I remember well enough that question to remember that nothing is revealed. Like you're not like, oh, like I see the architecture underneath the edifice or whatever. Yeah. I think it's probably only become riskier if time does to him what time does to us all. Here's what I hope happens. I hope so. I hope he does the ice bucket challenge. Somebody once again pours the ice water all over his head and he nominates Kim Jong-un and Vladimir Putin. And then we're just. Okay. That is what was going around in my group chats this week. Casey, you're next. What's going on in your group chats? Okay. So in my group chat, Kevin, at PJ, we are all talking about a story that I like to call. You can't lick a badger twice. You can't lick a badger twice. What is this story? So friend of the show, Katie Nautopolis wrote a piece about this over at business insider and basically people discovered that if you typed in almost any phrase into Google and added the word meaning, Google's AI systems would just create a meaning for you on the spot. And I think the basic idea was Google was like, well, let's, you know, people are always searching for the explanations of various phrases. We could direct them to the websites that would sort of answer that question. But actually, no way. Why don't we just use these AI overviews to tell people what these things mean? And if we don't know, we will just make it up. And so what people want from Google is a confident robot liar. That's right. So I know you guys are wondering, which is what did Google say when people asked for the meaning of you can't lick a badger twice? Please. What did it say? It's according to the AI overview. It means you can't trick or deceive someone a second time after they've been tricked once. It's a warning that if someone has already been deceived, they are unlikely to fall for the same trick again. Which like, no, that's not a thing. It doesn't mean that. It doesn't mean that. Some of the other great ones that people were trying out, you can't fit a duck in a pencil. I mean, you can't. No, actually, you know, PJ, you're onto what the AI was going to explain, which was according to Google, that's a simple idiom used to illustrate that something is impossible or logical. God, somebody else put up. This is one of my new favorite phrases. The road is full of salsa, which according to Google, likely refers to a vibrant and lively cultural scene, particularly a place where salsa music and dance are prevalent. Yeah. See, if this had come up in my group chats, this would have been immediately followed by someone changing the name of the group chat to the road is full of salsa. Did that happen in your chat, Casey? You know what? I have to say a part of my group chat culture is that we rarely change the name of the group chat. I think it would be very fun if we did and maybe I'll try it out, but we've really been sticking with the core names we've had. Are you willing to review? So, I guess, and we'll have to cut it because it's so busy and, but basically, when my, all my current friend group started forming, we noticed that they made very convenient little acronym. So, like, I'm in a group chat with like a Jacob Alex Casey Corey, and that just became Jack, for example, right? Yeah. Then Jack became Jackal. Then our friend Leon got married. So, we said we're going to move the L to the front. So, it became Lajak to sort of celebrate L. Then my boyfriend got a job at Antropics. So, the current name of the group chat is Lajakal from. So, unfortunately, that doesn't make any sense. But here's what I think is so interesting about this. These models have gone out and they have read the entire internet. They know what people say and they know what people don't say. So, you think it would be easy for them to just say, nobody says, you can't look at Badger twice. It's the weirdest thing that, like, the one thing you can't teach that AI computers coming for us all is just like humility. Like, you can't ever just feel like, I don't know. I don't know. Maybe you should like it up. But I think it actually ties in with something that we talked about earlier in the show, which is that these systems are so desperate to please you, that they do not want to irritate you by telling you that nobody says you can't look about her twice. And so, instead, they just go out and they make something up. Yeah. It reminds me a little bit. Do you remember either of you Google Wacking? Was that when you tried to find something that had no search results or one search result or something? Yeah. So, was this like long-running internet game where you would try to come up with a series of words or maybe two words, then when you typed them into Google, they would only return a single result. And so there are lots of people trying this out. There's like a whole Wikipedia page for Google Wacking. This sort of feels like the modern AI equivalent of that is like, can you come up with an idiom that is so stupid that Google's AI overview will not attempt to fill in a fake meeting? Yeah. And it's a great reminder that parents need to talk to their teens about Google Wacking in glazing. The two top terms of this week. Yeah. I'm sure their team doesn't have a bad thing. So, they should only look at once. Okay. Now, PJ, what have you brought us today from your group chats? Okay. So, the thing that I've been putting into all my group chats because I can't make sense of it is, um, you're a guy's colleague as we're crying. I don't know if you know it's this he was on some podcasts in the last month. A couple, a couple. And in one of the appearances he was being interviewed by Tyler Cowan, who's work in Relaydmire. And then they both agreed on this fact. Whereas like, wait, we all agree on this fact now. We're Tyler said that Sam Altman of Open AI had it some point predicted that in the not-too-distant future, we would have $1 billion company. Like, how many of those valued $1 billion? That only had one employee. Like, the implication being, you would train an AI to do something you're just like, count the money for the rest of your life. And PJ, I actually believe we have a clip of this ready to go. I'm struck by how small many companies can become. So, a mid-Journey, which you're familiar with, at the peak of its innovation, was eight people. And that was not mainly a story about consultants. Sam Altman says it will be possible to have $1 billion companies run by one person. I suspect that's two or three people. But nonetheless, that seems not so far off. So it seems to me they're really ought to be significant parts of the government by no means all, where you could have a much smaller number of people directing the AI. Is it would be the same people at the top giving the orders as today more or less? And just a lot fewer staff. I don't see how that can't be the case. I think that the, I agree with you that in theory should be the case. But I do think that as you actually see it emerge from, like, in theory should be the case to be figured out a way to do it, it's going to turn out that things of federal government does are not all that like, like, type up. But it's so hard to get rid of the thing. People, don't you need to start with it? Okay. So setting aside whether we should replace the federal government with lots of AI. The reason I was injecting this into all my group chats was I was just like guys, if the conversation is among people who are quite smart and who've spent a lot of time thinking about this, if they are predicting a world where AI replaces this much of the work force this fast, like, how are you guys thinking about it? But every group chat I put this into, the response instead was what is your idea for a billion dollar company? And any good ideas in there you want to share or maybe sort of get the creative juices flowing for our listeners. All the ideas I heard were profoundly unethical. Many of them seem to start with doing homework for children. It's a billion dollar idea and would I think a lot of AI companies are already making money? Yeah, that company exists and it is called OpenAI. It is a great thought experiment though. I think many of us have had thoughts over the years of maybe I'll go out and start a company, strike out on my own, do the three people in this chat actually did it. But getting to a billion dollars is not trivial and it is kind of tantalizing to imagine once you put AI at my fingertips will I be able to get there? Yeah, I mean, I actually this is giving me an idea for a maybe a billion dollar one person start up which is based on some of the ideas we talked about earlier in this show about how these models are becoming more flattering and persuasive, which is you know we all have that that that friend or maybe those friends who are totally addicted to posting and the internet and social media have wrecked their brain and are going to be to a shell of their former self. I know we're going to like it so much and I think we should create fake social networks for these people. Oh my god, it's so good and installed them on their phones so that they could be going to what they think is X or Facebook or TikTok and instead of hearing from their real horrible internet friends, they would sort of have these persuasive AI chat bots who say like maybe tone it down with the like racism and maybe you know gradually over the course of time sort of bring them back to base reality. What do you think about this idea? I like it so much. There are so many people I would build a little mirror world for where they could just like slowly become more sane and it's like hey all the retweets you want, all the likes you want you can be like the Elon Musk of this platform you could be like the drone suit guy this one or whatever but like the the trade office that it has to slowly slowly make you more sane instead of the opposite. Yes and I'm I worry that that is not possible because I think for you know a lot of the world's billionaires the existing social networks already served this purpose no matter what they say they have a thousand comments saying oh OMG you're so true for that bestie right and it does seem to have driven them completely insane so if we are able to somehow develop some anti radicalizing technology I do agree that can be a billion dollar company. Yeah what do you call what do you call that? Well also I like the term heaven banning which went viral a few years ago which is basically this idea that instead of being shadow banned you would get heaven ban which is you sort of like get banished to a platform where AI models just constantly agree with you and praise you and this would be a way to sort of bring people back from the brink so we can call it heaven ban. We just spent 30 minutes talking about how when you have AI's constantly tell people what they want to fake and drive them insane. No this is for people who are already insane. This is to try to try to rehabilitate them. I tried to have a talk with an AI operator this week asking it to stop complimenting me and truly it was like it's so good that you say that. Yeah the AI always comes back and keeps trying to flatter me and I say listen buddy you can't lick a badge or twice okay. Well PJ thank you for bringing us some gossip and content from your group chats and we should be in a group chat together with three of us. Yeah that sounds wonderful. Let's start one happy chatting PJ thanks guys. Music Hard fork is produced by Whitney Jones and Rachel Cone. We're edited this week by Matt Collette. We're fact checked by Ina Alvarado. Today's show is engineered by Chris Wood. Original music by Alicia Betytube, Diane Wong, Rowan Nemisto and Dan Powell. Our executive producer is Jen Plionts. Video production by Sawyer Row Kay, Amy Marino and Chris Shot. You can watch this full episode on YouTube at youtube.com slash hard fork. Special thanks to Paula Schumann, Wewing Tim, Dahlia Hadad and Jeff from Renda. As always you can email us at hard fork at nytimes.com. Invite us to your secret group chats.